{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% Imports\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% CONSTANTS\n",
    "N_SAMP = 10000\n",
    "BINS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PDFs of normal distributions with different parameters\n",
    "Too high or too low $\\sigma$ parameter can make histogram hardly informative (especially when using 'density') option. Changing scale of x-axis is one option to fight it but it distorts proportions between distributions with different parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "mu = [-15, 0, 15]\n",
    "sigma = [0.1, 0.316, 1, 3.16]\n",
    "\n",
    "for _mu in mu:\n",
    "    for _sigma in sigma:\n",
    "        df.loc[:,r'{},{}'.format(_mu, _sigma)] = \\\n",
    "        np.random.normal(loc=_mu, scale=_sigma, size=N_SAMP)\n",
    "        \n",
    "melted = pd.melt(df)\n",
    "\n",
    "temp = melted.loc[:,'variable'].str.split(',', expand=True)\n",
    "melted.loc[:,r'$\\mu$'] = temp[0]\n",
    "melted.loc[:,r'$\\sigma$'] = temp[1]\n",
    "del temp\n",
    "melted.drop(columns=['variable'])\n",
    "\n",
    "f = sns.FacetGrid(melted, col=r'$\\mu$', row=r'$\\sigma$')\n",
    "f = f.map(plt.hist, 'value')\n",
    "\n",
    "f = sns.FacetGrid(melted, col=r'$\\mu$', row=r'$\\sigma$')\n",
    "f = f.map(plt.hist, 'value', density=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Changing the $\\mu$ (mean) parameter changes the location of a peak in observations.\n",
    "- Changing the $\\sigma $ (standard deviation) parameter changes the dispersion of observations.\n",
    "- Changing the histogram mode to density will result in returning counts normalized to form a probability density (their sum will be equal to $1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Changing bin size for histiogram\n",
    "\n",
    "Higher bin sizes give better view on shape of PDS's shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = (np.round(np.logspace(0, 1, 5)*5)).astype(int)\n",
    "bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in bins:\n",
    "    f = sns.FacetGrid(melted, col='$\\mu$', row='$\\sigma$')\n",
    "    f = f.map(plt.hist, 'value', bins = b )\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting a proper bins number (or providing proper bin intervals) is crucial for how informative the will be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CDF for normal distrubution\n",
    "\n",
    "In polish \"Dystrybuanta\". \n",
    "\n",
    "When:\n",
    "\n",
    "$p(x)$ - is a PDF\n",
    "\n",
    "Then:\n",
    "\n",
    "$P(x)=\\int_{-\\infty}^{x}p(u)du$ - is it's CDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = sns.FacetGrid(melted, col=r'$\\mu$', row=r'$\\sigma$')\n",
    "f = f.map(plt.hist, 'value', cumulative=True)\n",
    "f = sns.FacetGrid(melted, col='$\\mu$', row='$\\sigma$')\n",
    "f = f.map(plt.hist, 'value', density = True, cumulative=True, bins=BINS)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " CDF are convinient when specifying a probability of variable X being in given interval $Prob(a<X<b)=P(b)-P(a)$ where P(x) is a CDF for given distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inverse LOGIT usage\n",
    "\n",
    "Logit function trnasforms a $(0; 1)$ interval into $(-\\infty; +\\infty)$\n",
    "\n",
    "Inverse logit function trnasforms a $(-\\infty; +\\infty)$ interval into $(0; 1)$ \n",
    "\n",
    "It helps when PDFs are spread widely, by cumulating them in $(0; 1)$ interval. Also it affects negatively PDFs that aren't centered around 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "melted_logit = melted.copy()\n",
    "melted_logit.loc[:,'value'] = sp.special.expit(melted_logit.loc[:,'value'])\n",
    "\n",
    "\n",
    "f = sns.FacetGrid(melted_logit, col=r'$\\mu$', row=r'$\\sigma$')\n",
    "f = f.map(plt.hist, 'value', bins=BINS)\n",
    "\n",
    "\n",
    "f = sns.FacetGrid(melted_logit, col=r'$\\mu$', row=r'$\\sigma$')\n",
    "f = f.map(plt.hist, 'value', cumulative=True, bins=BINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson's Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p = pd.DataFrame()\n",
    "\n",
    "lam = [1, 4, 10, 40]\n",
    "bins = [3, 4, 10, 40]\n",
    "b = [] \n",
    "\n",
    "def natural_hist(x, naturalBins=True, **kwargs):\n",
    "    if naturalBins:\n",
    "        bins = np.linspace(x.min(), x.max()+1, ((x.max()-x.min())+2) )\n",
    "    else:\n",
    "        bins = None\n",
    "    plt.hist(x, bins=bins, **kwargs)\n",
    "\n",
    "for _lam in lam:   \n",
    "    df_p.loc[:,'{}'.format(_lam)] = np.random.poisson(lam=_lam, size=N_SAMP)\n",
    "    \n",
    "melted_poisson = df_p.melt()\n",
    "\n",
    "melted_poisson.rename(columns={'variable': r'$\\lambda$'}, inplace=True)\n",
    "\n",
    "f = sns.FacetGrid(melted_poisson, col=r'$\\lambda$', col_wrap=2)\n",
    "f = f.map(natural_hist, 'value', cumulative=True)\n",
    "    \n",
    "f = sns.FacetGrid(melted_poisson, col=r'$\\lambda$', col_wrap=2)\n",
    "f = f.map(natural_hist, 'value')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poisson's distributions are conviniet tool for describing a number of occurances of certain phenomena in given time frame (for example occurances of plane accidents in a year) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beta distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ab = pd.DataFrame()\n",
    "\n",
    "alpha = [0.1, 0.316, 1, 3.16, 10]\n",
    "beta = [0.1, 0.316, 1, 3.16, 10]\n",
    "\n",
    "for _alpha in alpha:\n",
    "    for _beta in beta:\n",
    "        df_ab.loc[:,r'{},{}'.format(_alpha, _beta)] = \\\n",
    "        np.random.beta(a=_alpha, b=_beta, size=N_SAMP)\n",
    "\n",
    "melted_ab = df_ab.melt()\n",
    "\n",
    "temp = melted_ab.loc[:,'variable'].str.split(',', expand=True)\n",
    "melted_ab.loc[:,r'$\\alpha$'] = temp[0]\n",
    "melted_ab.loc[:,r'$\\beta$'] = temp[1]\n",
    "del temp\n",
    "melted_ab.drop(columns=['variable'])\n",
    "\n",
    "f = sns.FacetGrid(melted_ab,\\\n",
    "                  col=r'$\\alpha$', col_order=list(str(i) for i in alpha), \\\n",
    "                  row=r'$\\beta$', row_order=list(str(i) for i in beta) )\n",
    "f = f.map(plt.hist, 'value', bins=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beta distribution is constrained to $(0, 1)$ interval. Setting $\\alpha, \\beta = 1$ will result in uniform PDF. Setting parameters below $1$ will result in more samples near the interval ends. Setting high parameter values will result in more samples far the interval ends. $\\alpha$ parameter determines left side of PDF's curve shape, where as $\\beta$ the right side."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-Population parametrization\n",
    "\n",
    "$\\alpha = \\mu\\cdot N$\n",
    "\n",
    "$\\beta = N-\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mp = pd.DataFrame()\n",
    "\n",
    "mean = [0.1, 0.33, 0.5, 0.67, 0.9] # \\in (0; 1) \n",
    "population = [10, 100, 1000, 10000] # \\in (0; \\inf)\n",
    "\n",
    "for _mu in mean:\n",
    "    for _N in population:\n",
    "        a = _mu*_N\n",
    "        b = _N - a\n",
    "        df_mp.loc[:,r'{},{}'.format(_mu, _N)] = \\\n",
    "        np.random.beta(a=a, b=b, size=N_SAMP)\n",
    "\n",
    "melted_mp = df_mp.melt()\n",
    "\n",
    "temp = melted_mp.loc[:,'variable'].str.split(',', expand=True)\n",
    "melted_mp.loc[:,r'$\\mu$'] = temp[0]\n",
    "melted_mp.loc[:,r'$N$'] = temp[1]\n",
    "del temp\n",
    "melted_mp.drop(columns=['variable'])\n",
    "\n",
    "f = sns.FacetGrid(melted_mp, sharey=False,\\\n",
    "                  col=r'$\\mu$', col_order=list(str(i) for i in mean),\\\n",
    "                  row=r'$N$', row_order=list(str(i) for i in population))\n",
    "f = f.map(plt.hist, 'value', bins=BINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Location-Dispersion parametrization\n",
    "\n",
    "$\\alpha = \\frac{1-\\psi}{\\psi}\\cdot\\mu$\n",
    "\n",
    "$\\beta = \\frac{1-\\psi}{\\psi}\\cdot(1-\\mu)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ld = pd.DataFrame()\n",
    "\n",
    "mean = [0.1, 0.33, 0.5, 0.67, 0.9] # \\in (0; 1) \n",
    "dispersion = [0.01, 0.1, 0.33, 0.67] # \\in (0; 1)\n",
    "\n",
    "for _mu in mean:\n",
    "    for _psi in dispersion:\n",
    "        a = (1-_psi)/_psi*_mu\n",
    "        b = (1-_psi)/_psi*(1-_mu)\n",
    "        df_ld.loc[:,r'{},{}'.format(_mu, _psi)] = \\\n",
    "        np.random.beta(a=a, b=b, size=N_SAMP)\n",
    "\n",
    "melted_ld = df_ld.melt()\n",
    "\n",
    "temp = melted_ld.loc[:,'variable'].str.split(',', expand=True)\n",
    "melted_ld.loc[:,r'$\\mu$'] = temp[0]\n",
    "melted_ld.loc[:,r'$\\psi$'] = temp[1]\n",
    "del temp\n",
    "melted_ld.drop(columns=['variable'])\n",
    "\n",
    "f = sns.FacetGrid(melted_ld, \\\n",
    "                  col=r'$\\mu$', col_order=list(str(i) for i in mean), \\\n",
    "                  row=r'$\\psi$', row_order=list(str(i) for i in dispersion))\n",
    "f = f.map(plt.hist, 'value', bins=BINS*2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean, dispersion - parametrizaton gives control over location of mean of samples generated by the distribution. Settin higher mean parameter will result in PDF being more skewed to the right (and vice-versa). Setting low dispersion results in PDF being more concentrated around the mean (and also vice-versa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log-normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ln = pd.DataFrame()\n",
    "mu = [-1, 0, 1]\n",
    "sigma = [0.1, 0.316,1]\n",
    "\n",
    "for _mu in mu:\n",
    "    for _sigma in sigma:\n",
    "        df_ln.loc[:,r'{},{}'.format(_mu, _sigma)] = \\\n",
    "        np.random.lognormal(mean=_mu, sigma=_sigma, size=N_SAMP)\n",
    "        \n",
    "melted_ln = df_ln.melt()\n",
    "\n",
    "temp = melted_ln.loc[:,'variable'].str.split(',', expand=True)\n",
    "melted_ln.loc[:,r'$\\mu$'] = temp[0]\n",
    "melted_ln.loc[:,r'$\\sigma$'] = temp[1]\n",
    "del temp\n",
    "melted_ln.drop(columns=['variable'])\n",
    "\n",
    "def my_hist(x, FD_Bins=True, **kwargs):\n",
    "    if FD_Bins:\n",
    "        h = 2*(np.percentile(x, 75)-np.percentile(x, 25))/N_SAMP**(1/3)\n",
    "        b = int( np.ceil( (x.max()-x.min())/h ) )\n",
    "        bins = np.linspace(x.min(), x.max()+1, b )\n",
    "    else:\n",
    "        bins = None\n",
    "    plt.hist(x, bins=bins, **kwargs)\n",
    "\n",
    "f = sns.FacetGrid(melted_ln, col=r'$\\mu$', row=r'$\\sigma$', sharex=False)\n",
    "f = f.map(plt.hist, 'value', bins=BINS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Samples generated from Log Normal distribution are de facto exponentials of samples drawn from Normal distribution, so samples are concentrated around $e^{\\mu}$. A natural cause of this is also the fact that right tail of the curve is wider than it's left."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}